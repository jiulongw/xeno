#!/usr/bin/env bun

import fs from "node:fs";
import { promises as fsp } from "node:fs";
import os from "node:os";
import path from "node:path";
import { spawnSync } from "node:child_process";

const CONFIG_PATH = path.join(os.homedir(), ".config/xeno/config.json");
const TTS_MODEL_DEFAULT = "eleven_multilingual_v2";
const ASR_MODEL_DEFAULT = "scribe_v2";
const TTS_OUTPUT_FORMAT_DEFAULT = "mp3_44100_128";
const TTS_VOICE_ID_DEFAULT = "tOuLUAIdXShmWH7PEUrU";
const LOAD_API_KEY_ERROR = Symbol("load-api-key-error");

function printErr(message) {
  console.error(message);
}

function expandUser(inputPath) {
  if (!inputPath) {
    return inputPath;
  }
  if (inputPath === "~") {
    return os.homedir();
  }
  if (inputPath.startsWith("~/")) {
    return path.join(os.homedir(), inputPath.slice(2));
  }
  return inputPath;
}

async function loadApiKey({ allowMissing = false } = {}) {
  if (!fs.existsSync(CONFIG_PATH)) {
    if (allowMissing) {
      return null;
    }
    printErr(
      `error: config file not found at ${CONFIG_PATH} (expected field: elevenlabs_api_key)`,
    );
    return null;
  }

  let data;
  try {
    data = JSON.parse(await fsp.readFile(CONFIG_PATH, "utf8"));
  } catch (error) {
    if (error instanceof SyntaxError) {
      printErr(`error: invalid JSON in ${CONFIG_PATH}: ${error.message}`);
    } else {
      printErr(`error: unable to read ${CONFIG_PATH}: ${error}`);
    }
    return LOAD_API_KEY_ERROR;
  }

  const apiKey = data?.elevenlabs_api_key;
  if (typeof apiKey !== "string" || apiKey.trim() === "") {
    if (allowMissing) {
      return null;
    }
    printErr(`error: elevenlabs_api_key is missing or empty in ${CONFIG_PATH}`);
    return null;
  }

  return apiKey.trim();
}

async function getHttpErrorMessage(response) {
  const raw = (await response.text()).trim();
  let details = raw;

  try {
    const payload = JSON.parse(raw);
    if (payload && typeof payload === "object") {
      const detail = payload.detail;
      if (typeof detail === "string" && detail) {
        details = detail;
      } else if (detail !== undefined) {
        details = JSON.stringify(detail);
      }
    }
  } catch {
    // Preserve original response text when body is not JSON.
  }

  return details;
}

function usage() {
  console.log(`xeno-voice\n\nUsage:\n  xeno-voice say <message> -o <path> [--voice-id <id>] [--model-id <id>] [--output-format <fmt>]\n  xeno-voice asr -f <audio_or_video_path> [--model-id <id>]\n\nCommands:\n  say   Text-to-speech\n  asr   Automatic speech recognition to text`);
}

function sayUsage() {
  console.log(`Usage: xeno-voice say <message> -o <path> [options]\n\nOptions:\n  -o, --out-file <path>         Output audio file path (required)\n  -v, --voice-id <id>           ElevenLabs voice ID (default: ${TTS_VOICE_ID_DEFAULT})\n      --model-id <id>           TTS model ID (default: ${TTS_MODEL_DEFAULT})\n      --output-format <format>  TTS output format (default: ${TTS_OUTPUT_FORMAT_DEFAULT})`);
}

function asrUsage() {
  console.log(`Usage: xeno-voice asr -f <audio_or_video_path> [options]\n\nOptions:\n  -f, --file <path>    Input audio/video file path (required)\n      --model-id <id>  ASR model ID (default: ${ASR_MODEL_DEFAULT})`);
}

function parseValue(argv, index, optionName) {
  const value = argv[index + 1];
  if (!value || value.startsWith("-")) {
    throw new Error(`missing value for ${optionName}`);
  }
  return value;
}

function parseSayArgs(argv) {
  const args = {
    message: null,
    voiceId: TTS_VOICE_ID_DEFAULT,
    outFile: null,
    modelId: TTS_MODEL_DEFAULT,
    outputFormat: TTS_OUTPUT_FORMAT_DEFAULT,
  };

  const positionals = [];

  for (let i = 0; i < argv.length; i += 1) {
    const token = argv[i];

    if (token === "-h" || token === "--help") {
      sayUsage();
      return { help: true };
    }

    if (token === "-v" || token === "--voice-id") {
      args.voiceId = parseValue(argv, i, token);
      i += 1;
      continue;
    }

    if (token === "-o" || token === "--out-file") {
      args.outFile = parseValue(argv, i, token);
      i += 1;
      continue;
    }

    if (token === "--model-id") {
      args.modelId = parseValue(argv, i, token);
      i += 1;
      continue;
    }

    if (token === "--output-format") {
      args.outputFormat = parseValue(argv, i, token);
      i += 1;
      continue;
    }

    if (token.startsWith("-")) {
      throw new Error(`unknown option for say: ${token}`);
    }

    positionals.push(token);
  }

  if (positionals.length !== 1) {
    throw new Error("say expects exactly one positional <message>");
  }
  if (!args.outFile) {
    throw new Error("say requires -o/--out-file");
  }

  args.message = positionals[0];
  return args;
}

function parseAsrArgs(argv) {
  const args = {
    file: null,
    modelId: ASR_MODEL_DEFAULT,
  };

  for (let i = 0; i < argv.length; i += 1) {
    const token = argv[i];

    if (token === "-h" || token === "--help") {
      asrUsage();
      return { help: true };
    }

    if (token === "-f" || token === "--file") {
      args.file = parseValue(argv, i, token);
      i += 1;
      continue;
    }

    if (token === "--model-id") {
      args.modelId = parseValue(argv, i, token);
      i += 1;
      continue;
    }

    if (token.startsWith("-")) {
      throw new Error(`unknown option for asr: ${token}`);
    }

    throw new Error(`unexpected positional argument for asr: ${token}`);
  }

  if (!args.file) {
    throw new Error("asr requires -f/--file");
  }

  return args;
}

function parseCli(argv) {
  if (argv.length === 0 || argv[0] === "-h" || argv[0] === "--help") {
    usage();
    return { help: true };
  }

  const command = argv[0];
  const rest = argv.slice(1);

  if (command === "say") {
    return { command, args: parseSayArgs(rest) };
  }
  if (command === "asr") {
    return { command, args: parseAsrArgs(rest) };
  }

  throw new Error(`unknown command: ${command}`);
}

async function runSay(args, apiKey) {
  const outPath = path.resolve(expandUser(args.outFile));

  try {
    await fsp.mkdir(path.dirname(outPath), { recursive: true });
  } catch (error) {
    printErr(`error: unable to create parent directory for ${outPath}: ${error}`);
    return 1;
  }

  if (!apiKey) {
    if (process.platform !== "darwin") {
      printErr(
        "error: elevenlabs_api_key is not configured and macOS `say` fallback is only available on macOS",
      );
      return 1;
    }

    printErr("info: elevenlabs_api_key is missing; using macOS `say` fallback");

    const sayArgs = [];
    if (args.voiceId !== TTS_VOICE_ID_DEFAULT) {
      sayArgs.push("-v", args.voiceId);
    }
    sayArgs.push(args.message, "-o", outPath);

    const result = spawnSync("say", sayArgs, {
      encoding: "utf8",
    });

    if (result.error) {
      if (result.error.code === "ENOENT") {
        printErr("error: unable to find `say` in PATH for fallback TTS");
      } else {
        printErr(`error: macOS \`say\` command failed: ${result.error.message}`);
      }
      return 1;
    }

    if (result.status !== 0) {
      const details = result.stderr?.trim() || result.stdout?.trim();
      if (details) {
        printErr(`error: macOS \`say\` command failed: ${details}`);
      } else {
        printErr("error: macOS `say` command failed");
      }
      return 1;
    }

    return 0;
  }

  const requestUrl = new URL(`https://api.elevenlabs.io/v1/text-to-speech/${args.voiceId}`);
  requestUrl.searchParams.set("output_format", args.outputFormat);

  let response;
  try {
    response = await fetch(requestUrl, {
      method: "POST",
      headers: {
        "xi-api-key": apiKey,
        accept: "audio/mpeg",
        "content-type": "application/json",
      },
      body: JSON.stringify({
        text: args.message,
        model_id: args.modelId,
      }),
      signal: AbortSignal.timeout(120_000),
    });
  } catch (error) {
    printErr(`error: failed to call ElevenLabs TTS API: ${error}`);
    return 1;
  }

  if (!response.ok) {
    const details = await getHttpErrorMessage(response);
    printErr(`error: ElevenLabs TTS request failed (${response.status}): ${details}`);
    return 1;
  }

  try {
    const body = new Uint8Array(await response.arrayBuffer());
    await Bun.write(outPath, body);
  } catch (error) {
    printErr(`error: unable to write output file ${outPath}: ${error}`);
    return 1;
  }

  return 0;
}

function extractTranscriptText(payload) {
  if (typeof payload?.text === "string" && payload.text.trim() !== "") {
    return payload.text;
  }

  if (Array.isArray(payload?.transcripts)) {
    const parts = [];
    for (const item of payload.transcripts) {
      const chunk = item?.text;
      if (typeof chunk === "string" && chunk.trim() !== "") {
        parts.push(chunk.trim());
      }
    }
    if (parts.length > 0) {
      return parts.join("\n");
    }
  }

  return null;
}

function parsePositiveNumber(rawValue, envName) {
  const value = Number(rawValue);
  if (!Number.isFinite(value)) {
    throw new Error(`error: invalid ${envName} value; expected a positive number`);
  }
  if (value <= 0) {
    throw new Error(`error: invalid ${envName} value; must be > 0`);
  }
  return value;
}

function runMacosDictationAsr(audioPath) {
  if (process.platform !== "darwin") {
    printErr(
      "error: elevenlabs_api_key is not configured and macOS dictation fallback is only available on macOS",
    );
    return 1;
  }

  const timeoutRaw = process.env.XENO_VOICE_MACOS_ASR_TIMEOUT_SECONDS ?? "30";
  let timeoutSeconds;
  try {
    timeoutSeconds = parsePositiveNumber(timeoutRaw, "XENO_VOICE_MACOS_ASR_TIMEOUT_SECONDS");
  } catch (error) {
    printErr(String(error.message || error));
    return 1;
  }

  const swiftSource = String.raw`
import Foundation
import Speech

func fail(_ message: String) -> Never {
    FileHandle.standardError.write((message + "\n").data(using: .utf8)!)
    exit(1)
}

guard CommandLine.arguments.count >= 2 else {
    fail("missing input file path")
}

let inputURL = URL(fileURLWithPath: CommandLine.arguments[1])
guard FileManager.default.fileExists(atPath: inputURL.path) else {
    fail("input file not found: \(inputURL.path)")
}

guard let recognizer = SFSpeechRecognizer(locale: Locale.current) ?? SFSpeechRecognizer() else {
    fail("Speech recognizer is unavailable on this system")
}

let timeoutSeconds = Double(ProcessInfo.processInfo.environment["XENO_VOICE_MACOS_ASR_TIMEOUT_SECONDS"] ?? "") ?? 30

var status = SFSpeechRecognizer.authorizationStatus()
if status == .notDetermined {
    let authDeadline = Date().addingTimeInterval(15)
    SFSpeechRecognizer.requestAuthorization { newStatus in
        status = newStatus
    }
    while status == .notDetermined && Date() < authDeadline {
        RunLoop.current.run(mode: .default, before: Date().addingTimeInterval(0.1))
    }
}

guard status == .authorized else {
    fail("Speech recognition is not authorized (status=\(status.rawValue)). Allow this app in System Settings > Privacy & Security > Speech Recognition.")
}

let request = SFSpeechURLRecognitionRequest(url: inputURL)
request.shouldReportPartialResults = false
if #available(macOS 13.0, *) {
    request.addsPunctuation = true
}

var transcript: String?
var recognitionError: Error?
var isDone = false

let task = recognizer.recognitionTask(with: request) { result, error in
    if let result = result {
        transcript = result.bestTranscription.formattedString
        if result.isFinal {
            isDone = true
        }
    }

    if let error = error {
        recognitionError = error
        isDone = true
    }
}

let deadline = Date().addingTimeInterval(timeoutSeconds)
while !isDone && Date() < deadline {
    RunLoop.current.run(mode: .default, before: Date().addingTimeInterval(0.1))
}
task.cancel()

if !isDone {
    fail("speech recognition timed out")
}

if let recognitionError = recognitionError {
    fail("speech recognition error: \(recognitionError.localizedDescription)")
}

guard let transcript = transcript?.trimmingCharacters(in: .whitespacesAndNewlines), !transcript.isEmpty else {
    fail("no transcript text produced")
}

print(transcript)
`;

  const env = {
    ...process.env,
    SWIFT_MODULECACHE_PATH: process.env.SWIFT_MODULECACHE_PATH ?? "/tmp/swift-module-cache",
    CLANG_MODULE_CACHE_PATH: process.env.CLANG_MODULE_CACHE_PATH ?? "/tmp/clang-module-cache",
  };

  const result = spawnSync("swift", ["-", audioPath], {
    input: swiftSource,
    encoding: "utf8",
    env,
    timeout: Math.ceil((timeoutSeconds + 5) * 1000),
    maxBuffer: 1024 * 1024 * 10,
  });

  if (result.error) {
    if (result.error.code === "ENOENT") {
      printErr("error: unable to find `swift` in PATH for macOS dictation fallback");
      return 1;
    }
    if (result.error.code === "ETIMEDOUT") {
      printErr(
        "error: macOS dictation ASR timed out; check Speech Recognition permission and input audio format",
      );
      return 1;
    }
    printErr(`error: failed to execute macOS dictation fallback: ${result.error.message}`);
    return 1;
  }

  if (result.status !== 0) {
    const details = result.stderr?.trim() || result.stdout?.trim();
    if (details) {
      printErr(`error: macOS dictation ASR failed: ${details}`);
    } else {
      printErr("error: macOS dictation ASR failed");
    }
    return 1;
  }

  const transcript = result.stdout?.trim();
  if (!transcript) {
    printErr("error: macOS dictation ASR produced empty transcript");
    return 1;
  }

  console.log(transcript);
  return 0;
}

async function runAsr(args, apiKey) {
  const audioPath = path.resolve(expandUser(args.file));

  let stat;
  try {
    stat = await fsp.stat(audioPath);
  } catch {
    printErr(`error: audio file not found: ${audioPath}`);
    return 1;
  }

  if (!stat.isFile()) {
    printErr(`error: not a file: ${audioPath}`);
    return 1;
  }

  if (!apiKey) {
    printErr("info: elevenlabs_api_key is missing; using macOS dictation ASR fallback");
    return runMacosDictationAsr(audioPath);
  }

  const form = new FormData();
  form.set("model_id", args.modelId);
  const audioFile = Bun.file(audioPath);
  const mimeType = audioFile.type || "application/octet-stream";
  form.set("file", new File([audioFile], path.basename(audioPath), { type: mimeType }));

  let response;
  try {
    response = await fetch("https://api.elevenlabs.io/v1/speech-to-text", {
      method: "POST",
      headers: {
        "xi-api-key": apiKey,
      },
      body: form,
      signal: AbortSignal.timeout(300_000),
    });
  } catch (error) {
    printErr(`error: failed to call ElevenLabs ASR API: ${error}`);
    return 1;
  }

  if (!response.ok) {
    const details = await getHttpErrorMessage(response);
    printErr(`error: ElevenLabs ASR request failed (${response.status}): ${details}`);
    return 1;
  }

  let payload;
  try {
    payload = await response.json();
  } catch {
    printErr("error: ElevenLabs ASR response was not valid JSON");
    return 1;
  }

  if (!payload || typeof payload !== "object" || Array.isArray(payload)) {
    printErr("error: unexpected ElevenLabs ASR response shape");
    return 1;
  }

  const transcript = extractTranscriptText(payload);
  if (!transcript) {
    printErr("error: no transcript text found in ElevenLabs ASR response");
    return 1;
  }

  console.log(transcript);
  return 0;
}

async function main() {
  let parsed;
  try {
    parsed = parseCli(process.argv.slice(2));
  } catch (error) {
    printErr(`error: ${error.message || error}`);
    usage();
    return 1;
  }

  if (parsed.help || parsed.args?.help) {
    return 0;
  }

  const apiKey = await loadApiKey({ allowMissing: parsed.command === "say" || parsed.command === "asr" });
  if (apiKey === LOAD_API_KEY_ERROR) {
    return 1;
  }

  if (parsed.command === "say") {
    return runSay(parsed.args, apiKey);
  }

  if (parsed.command === "asr") {
    return runAsr(parsed.args, apiKey);
  }

  printErr(`error: unsupported command: ${parsed.command}`);
  return 1;
}

const code = await main();
process.exit(code);
